{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn import preprocessing","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Importando os dados:","metadata":{}},{"cell_type":"code","source":"adult_train = pd.read_csv(\"../input/adult-pmr3508/train_data.csv\",index_col=['Id'],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")\nadult_test = pd.read_csv(\"../input/adult-pmr3508/test_data.csv\",index_col=['Id'],\n        sep=r'\\s*,\\s*',\n        engine='python',\n        na_values=\"?\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adult_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adult_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vamos tratar os dados faltantes, primeiro identificando quais parâmetros apresentam dados faltantes.","metadata":{}},{"cell_type":"code","source":"Faltantes = adult_train.isnull().sum().sort_values(ascending = False)\nFaltantes.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train.workclass.value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Vamos atribuir a moda do parâmetro workclass nos dados faltantes dado que grande parte das pessoas trabalham no setor privado.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train['native.country'].value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A maior parte das pessoas desse banco de dados são americanas, é sensato retirar esse parâmetro para fazer o treinamento no fim já que esse parâmetro está muito enviesado para pessoas americanas, se quereremos fazer predição, como não sabemos se serão para americanos ou não é útil retirar esse parametro. No entanto, como a maior parte das pessoas desse banco de dados são americanos é conveninente atribuir a nacionalidade americana aos dados faltantes desse parâmetro.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train.occupation.value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Os dados de occupation são bem distribuídos, no entanto vou substituir os dados faltantes pela moda Prof-specialty mas poderia ser por exemplo Craft-repair por não serem estão distantes em número de ocorrência.","metadata":{}},{"cell_type":"markdown","source":"Completando com a moda:","metadata":{}},{"cell_type":"code","source":"adult_train[\"workclass\"] = adult_train[\"workclass\"].fillna(adult_train[\"workclass\"].describe().top)\nadult_train['native.country'] = adult_train['native.country'].fillna(adult_train['native.country'].describe().top);\nadult_train['occupation'] = adult_train['occupation'].fillna(adult_train['occupation'].describe().top);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Verificou-se todos os dados faltantes foram eliminados:","metadata":{}},{"cell_type":"code","source":"Faltantes = adult_train.isnull().sum().sort_values(ascending = False)\nFaltantes.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Realizando o mesmo para os dados de teste:","metadata":{}},{"cell_type":"code","source":"adult_test[\"workclass\"] = adult_test[\"workclass\"].fillna(adult_test[\"workclass\"].describe().top)\nadult_test['native.country'] = adult_test['native.country'].fillna(adult_test['native.country'].describe().top);\nadult_test['occupation'] = adult_test['occupation'].fillna(adult_test['occupation'].describe().top);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Faltantes = adult_test.isnull().sum().sort_values(ascending = False)\nFaltantes.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Agora, vou verificar como os parâmetros se relacionam com \"income\", selecionando os parâmetros mais importantes para o modelo final","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(15, 7))\nadult_train.groupby(\"income\").age.hist()\nplt.legend(['<=50k','>50k'])\nplt.xlabel('Age')\nplt.ylabel('quantity')\nplt.title('Age histogram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A maior parte das pessoas mais bem remuneradas estão na faixa dos 40 anos, é de se esperar dado que nessa idade que se atinge uma certa maturidade profissional. Vale observar que é bem possível que essa concentração nessa idade seja maior ainda do que a apresentada dado que grande parte das pessoas do banco de dados estão na faixa dos vinte anos ainda.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train['education.num'].value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O parametro education será eliminado dado que education.num representa a mesma informação. A maior parte das pessoas estã no nivel de educação 9, 10 e 13. Poucas pessoas tem qualificação superior a essas, mas também poucas pessoas tem abaixo dessas.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train['marital.status'].value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A maior parte dos dados correspondem a pessoas casadas ou não casadas.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train['occupation'].value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train['hours.per.week'].value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A maior parte das pessoas consultadas trabalham 40 horas por semana mas algumas passam disso podendo trabalhar até 60 horas.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train['capital.loss'].value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(17, 7))\nadult_train['capital.loss'].value_counts().plot(kind = 'pie')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Capital loss e gain não aparentam ser dados importantes pois quase ninguém dos dados apresentam esse tipo de investimento. Porém nos testes feitos retirá-los afeta negativamente o resultado final","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 7))\nadult_train.groupby(\"income\").workclass.hist()\nplt.legend(['<=50k','>50k'])\nplt.xlabel(\"Workclass\")\nplt.ylabel('quantity')\nplt.title('Workclass histogram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20, 7))\nadult_train.groupby(\"income\").relationship.hist()\nplt.legend(['<=50k','>50k'])\nplt.xlabel(\"Relationship Status\")\nplt.ylabel('Relationship Status')\nplt.title('Relationship histogram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A maior parte das pessoas bem remuneradas são maridos. No entanto esses dados parecem serem incompletos dado que poucas esposas foram consultadas. Porém pode-se aceitar esse resultado dado que posteriormente veremos que há uma desigualdade de gênero presente na remuneração e portanto em relação a estado civil maridos ganhariam mais do que esposas.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 7))\nadult_train.groupby(\"income\").race.hist()\nplt.legend(['<=50k','>50k'])\nplt.xlabel(\"Race Status\")\nplt.ylabel('Race Status')\nplt.title('Race histogram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"É possivel ver que as pessoas mais bem remuneradas desses dados são caucasianas, no entanto quase todas as pessoas consultadas são caucasianas. Seria interessante que esses dados tivessem mais representatividade de outras raças. Irei considerar esse parâmetro, no entanto ele não parece ser aceitável para países com mais diversidade cultural como o próprio Brasil.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 7))\nadult_train.groupby(\"income\").sex.value_counts().plot(kind = 'pie')\nplt.legend(['<=50k','>50k'])\nplt.xlabel(\"Sex Status\")\nplt.ylabel('Sex Status')\nplt.title('Sex histogram')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Como dito, os dados mostram uma desigualdade de gênero presente na sociedade na questão da remuneração. Das pessoas melhor remuneradas, a grande maioria são homens.","metadata":{}},{"cell_type":"markdown","source":"Aqui serão transformadas os parâmetros que não são numéricos em numéricos para poderem ser melhor trabalhados.","metadata":{}},{"cell_type":"code","source":"adult_train_num=adult_train.apply(preprocessing.LabelEncoder().fit_transform)\nadult_test_num=adult_test.apply(preprocessing.LabelEncoder().fit_transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"adult_train_num.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Construindo então a matriz de correlação entre parâmetros:","metadata":{}},{"cell_type":"code","source":"rel = adult_train_num.drop(['income'],axis = 1)\nrel_bi = adult_train_num['income']\nrel = pd.concat([rel, rel_bi], axis = 1)\nplt.figure(figsize=(15,8))\nsns.heatmap(rel.corr(),annot=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dada a matriz de correlação vemos que parâmetros como horas trabalhas por semana, ganho capital, sexo, relacionamento, educação e idade são importantes para o modelo. Parâmetros como fnlwgt pode e vai ser desprezado, education também pois education.num representa a mesma informação e native.country dado que esse parâmetro está enviesado.","metadata":{}},{"cell_type":"markdown","source":"Por fim, os dados serão normalizados","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainX = adult_train_num[[\"age\",\"education.num\",\"capital.gain\", \"capital.loss\", \"hours.per.week\",\"occupation\",'relationship','race','sex','marital.status']]\ntrainY=adult_train.income\ntestX = adult_test_num[[\"age\",\"education.num\",\"capital.gain\", \"capital.loss\", \"hours.per.week\",\"occupation\",'relationship','race','sex','marital.status']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"normalizador = preprocessing.StandardScaler()\ntrainX = normalizador.fit_transform(trainX)\ntestX = normalizador.fit_transform(testX)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Irei testar vários tipos de classificadores:","metadata":{}},{"cell_type":"markdown","source":"# KNN","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\nmédia=0\nmaior_média=0\nmelhor_k=0\nfor K in range(1,50):\n    knn = KNeighborsClassifier(n_neighbors=K)\n    scores = cross_val_score(knn,trainX,trainY,cv=10)\n    média=scores.mean()\n    if(média>maior_média):\n        score_KNN=média\n        melhor_k=K","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"melhor_k","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=melhor_k)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"melhor_k","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_KNN","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes Gaussiano","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb = GaussianNB()\nscores = cross_val_score(nb,trainX,trainY,cv=10)\nscore_Naive_Bayes=scores.mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_Naive_Bayes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Regressão Logistica","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logreg = LogisticRegression(solver='liblinear',random_state=90)\nhyperparams = dict(C=np.linspace(0,10,100), penalty=['l2', 'l1'])              \nclassificador_lr = RandomizedSearchCV(logreg, hyperparams, n_iter=50, cv=2, n_jobs=-1, random_state=0, verbose=2)\nbusca_logreg = classificador_lr.fit(trainX, trainY)\nlr = LogisticRegression(solver='liblinear',random_state=90,C=busca_logreg.best_params_['C'],penalty=busca_logreg.best_params_['penalty'])\nscores = cross_val_score(lr,trainX,trainY,cv=10)\nscore_Linear_Regression=scores.mean()\nscore_Regressão_Logistica=busca_logreg.best_score_\nprint(score_Regressão_Logistica)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tentou-se melhorar o classificador através do AdaBoost","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier(base_estimator=LogisticRegression(solver='liblinear',random_state=90),random_state=90)\nhyperparams = dict(n_estimators=[50,100,150,200] ,learning_rate=[0.1,0.2,0.3,0.4,0.5,1,1.5])                     \nclassificador = RandomizedSearchCV(ada, hyperparams, n_iter=50, cv=2, n_jobs=-1, random_state=0, verbose=2)\nbusca = classificador.fit(trainX, trainY)\nlr_boosted = AdaBoostClassifier(base_estimator=LogisticRegression(solver='liblinear',random_state=90),random_state=90,n_estimators=busca.best_params_['n_estimators'] ,learning_rate=busca.best_params_['learning_rate'])\nscores = cross_val_score(lr_boosted,trainX,trainY,cv=10)\nscore_Linear_Regression_Boosted=scores.mean()\nprint(score_Linear_Regression_Boosted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"busca.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LDA e QDA","metadata":{}},{"cell_type":"code","source":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lda = LinearDiscriminantAnalysis()\nhyperparams = dict(store_covariance=['True','False'] ,solver=['svd', 'lsqr', 'eigen'])                   \nclassificador_lda = RandomizedSearchCV(lda, hyperparams, n_iter=50, cv=2, n_jobs=-1, random_state=0, verbose=2)\nbusca_lda = classificador_lda.fit(trainX,trainY)\nlda = LinearDiscriminantAnalysis(store_covariance=busca_lda.best_params_['store_covariance'] ,solver=busca_lda.best_params_['solver'])\nscores = cross_val_score(lda,trainX,trainY,cv=10)\nscore_LDA=scores.mean()\nprint(score_LDA)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qda = QuadraticDiscriminantAnalysis()\nhyperparams = dict(store_covariance=['True','False'] ,reg_param=[0,0.1, 0.2, 0.3, 0.4, 0.5,0.6,0.7,0.8,0.9,1])                     \nclassificador_qda = RandomizedSearchCV(qda, hyperparams, n_iter=50, cv=2, n_jobs=-1, random_state=0, verbose=2)\nbusca_qda = classificador_qda.fit(trainX, trainY)\nqda = QuadraticDiscriminantAnalysis(store_covariance=busca_qda.best_params_['store_covariance'] ,reg_param=busca_qda.best_params_['reg_param'])\nscores = cross_val_score(qda,trainX,trainY,cv=10)\nscore_QDA=scores.mean()\nprint(score_QDA)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Randon Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf=RandomForestClassifier()\nhyperparams = dict(criterion=['gini','entropy'] ,n_estimators=[100,150,200,250,300,350,400])                     \nclassificador_rf = RandomizedSearchCV(rf, hyperparams, n_iter=50, cv=2, n_jobs=-1, random_state=0, verbose=2)\nbusca_rf = classificador_rf.fit(trainX, trainY)\nrf = RandomForestClassifier(criterion=busca_rf.best_params_['criterion'] ,n_estimators=busca_rf.best_params_['n_estimators'])\nscores = cross_val_score(rf,trainX,trainY,cv=10)\nscore_rf=scores.mean()\nprint(score_rf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBOOST com árvore de classificação","metadata":{}},{"cell_type":"code","source":"pip install xgboost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from xgboost import XGBClassifier\nxgb = XGBClassifier(objective='binary:logistic',seed=90,subsample=0.9,colsample_bytree=0.5)\nhyperparams = dict(max_depth=[1,2,3,4,5,6,7,8,9,10],learning_rate=[0.01,0.05,0.1,0.3,0.5],reg_lambda=[0,1,10],scale_pos_weight=[1,3,5,6,7])                     \nclassificador_xgb = RandomizedSearchCV(xgb, hyperparams, n_iter=50, cv=3, n_jobs=-1, random_state=0, verbose=2,scoring='roc_auc')\nbusca_xgb = classificador_xgb.fit(trainX, trainY)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"busca_xgb.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb=XGBClassifier(objective='binary:logistic',seed=90,subsample=0.9,colsample_bytree=0.5,scale_pos_weight=busca_xgb.best_params_['scale_pos_weight'],reg_lambda=busca_xgb.best_params_['reg_lambda'],max_depth=busca_xgb.best_params_['max_depth'],learning_rate=busca_xgb.best_params_['learning_rate'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = cross_val_score(xgb,trainX,trainY,cv=10)\nscore_xgb=scores.mean()\nscore_xgb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ADABOOST com árvore de classificação","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier(random_state=90)\nhyperparams = dict(n_estimators=[50,100,150,200] ,learning_rate=[0.1,0.2,0.3,0.4,0.5,1,1.5])                     \nclassificador = RandomizedSearchCV(ada, hyperparams, n_iter=50, cv=2, n_jobs=-1, random_state=0, verbose=2)\nbusca = classificador.fit(trainX, trainY)\ntree_ada_boosted = AdaBoostClassifier(random_state=90,n_estimators=busca.best_params_['n_estimators'] ,learning_rate=busca.best_params_['learning_rate'])\nscores = cross_val_score(tree_ada_boosted,trainX,trainY,cv=10)\nscore_Tree_Ada=scores.mean()\nprint(score_Tree_Ada)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissão","metadata":{}},{"cell_type":"code","source":"knn.fit(trainX,trainY)\nnb.fit(trainX,trainY)\nlr.fit(trainX,trainY)\nlr_boosted.fit(trainX,trainY)\nlda.fit(trainX,trainY)\nqda.fit(trainX,trainY)\nrf.fit(trainX,trainY)\nxgb.fit(trainX, trainY)\ntree_ada_boosted.fit(trainX,trainY)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testY_knn=knn.predict(testX)\ntestY_nb=nb.predict(testX)\ntestY_lr=lr.predict(testX)\ntestY_lr_boosted=lr_boosted.predict(testX)\ntestY_lda=lda.predict(testX)\ntestY_qda=qda.predict(testX)\ntestY_rf=rf.predict(testX)\ntestY_xgb=xgb.predict(testX)\ntestY_tree_ada_boosted=tree_ada_boosted.predict(testX)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"O classificador com o melhor score foi XGBOOST com árvore de classificação usando os atributos considerados, retirando mais atributos foi verificado que o score é inferior.","metadata":{}},{"cell_type":"code","source":"submiss=pd.DataFrame(testY_xgb,columns=['income'])\nsubmiss.to_csv(\"PMR3508-2020-90_submissao.csv\", index_label=\"Id\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SCORES\nscore_knn=0.84680\n\nscore_nb=0.81861\n\nscore_lr=0.82346\n\nscore_lr_boosted=0.82217\n\nscore_lda=0.82039\n\nscore_qda=0.81971\n\nscore_rf=0.84305\n\nscore_xgb=0.86074\n\nscore_tree_ada_boosted=0.85233","metadata":{}},{"cell_type":"markdown","source":"# SCORES Considerando apenas os seguintes atributos:\n\n**Age,education.num,marital status, relationship, sex, capital gain, capital loss, hours per week**\n\nscore_knn=0.84944\n\nscore_nb=0.81443\n\nscore_lr=0.82321\n\nscore_lr_boosted=0.82248\n\nscore_lda=0.81959\n\nscore_qda=0.82076\n\nscore_rf=0.83986\n\nscore_xgb=0.75724\n\nscore_tree_ada_boosted=0.84563","metadata":{}}]}